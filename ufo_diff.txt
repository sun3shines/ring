
精简paste.deploy

研究下 capture_stdio 和 drop_privileges

目前是测试，因此可以大笔一挥了。统统不讲究了。 

目前只要单进程了。是的。

ring的核心，即md5标志符转为address，即2**32 整数集转为address了。

一般的整数集为10**9 

关于数据的重新分布

修改移动的ring的配置，做出标记了。且交给主机处理，被移动的虚结点了。

虚节点的数据，通过重新查找自己的md5，确定新的位置了。并进行移动了。是的。

记录被修改的虚节点，并判断数据移动的方向了？

数据到虚节点，是不变的。而移动的是虚节点的归属了？应该是的。

等于是重新上传文件了？

关于2**32和10**8的区别？首先，是需要把id散列在环上了。

因此，虚节点的meta首先来进行迁移了。是的。

然后是丰富ring的查找过程了。是的。

首先是源虚节点拷贝自己的meta集合到新虚节点上了。是的。

关于数据迁移，和备份了。是的。

下午的话，需要好好的设计下这个机制了。是的。

事情的发展都是在原有的内容上发展的。写旧的东西，只是为了促进新的发展了。是的。

重点是什么？是数据迁移的过程了。是否需要全局知道呢？首先是统计么？

会把统计列表发往各地的新地方了。是的。例如，uuid的标志符了。然后利用旧有的ring进行查询了。或者利用新ring进行上传了。还是旧有的ring去get吧，而不是新的ring去查询了。是的。

因此，ring的查询，不需要走proxy了。自身就可以来处理了。是的。新的服务新的处理了。是的。增加一个新的服务了。migrate服务了。是的。完成数据迁移了。是的。

和代理无关，代理只是对外的。是的。所以这些还是需要内部解决了。是的。

replica服务，启动后，检查新的ring，负责搜集，或者负责分发，并且负责io了。是的。migrate服务后，自动来检查这些了。是的。检查ring有无变化了。是的。ring的变化，只能增加不会减少了。是的。

replica
会检查ring，并根据ring左该做的事情了。目前的ring，可以集中放在proxy节点上，后续可以利用paxos来进行管理了。是的。

每个节点利用最新的ring，查找出，需要变换的ring，并把变化的虚节点和本机的上虚节点进行对照，查找那些需要变化了。是的。

ring的文件，会记录日期和序列号了。并且，记录uuid了。或者version了。是的。

先记录最高version了。以及次要的version了。如果差了好几个的version版本了。那就没辙了。

然后依次进行同步了。是的。

无限做是可以的，但是如果前一个没有做完，怎么办？

统计源码行数 find . -name "*.py" | xargs grep -v "^$" | wc -l
